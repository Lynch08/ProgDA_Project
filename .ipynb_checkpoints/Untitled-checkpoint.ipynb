{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4daaf75-bd07-4c96-a4a2-ec2d2d319e03",
   "metadata": {},
   "source": [
    "Lecturer: Dr Brian McGinley  \n",
    "Module: Programming For Data Analysis  \n",
    "Author: Enda Lynch  \n",
    "Github Username: Lynch08  \n",
    "GMIT Email: G003987951@gmit.ie  \n",
    "Personal Email: elyn@live.ie  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca18b60-7675-4f2f-80b9-e7b55b8f5ab8",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "This repository contains all of the files pertaining to my 2021 project submission for the Programming for Data Analysis module of the GMIT H.Dip program in Data Analytics. All of the work contained within this repository was carried out over the course of a 3 week period in August 2022. This Jupyter notebook contains the complete documentation for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d6ab6-e989-4516-a92e-4efc3776d4dc",
   "metadata": {},
   "source": [
    "### 1.1 Project objective\n",
    "The objective of this project is to synthesise a data set based on some real world phenomenon. This requires investigation in to the phenomenon and then using the numpy.random package in Python to simulated some data based on this. The problem statement for the assignment is as follows :\n",
    "\n",
    "1. Choose a real-world phenomenon that can be measured and for which you could collect at least one-hundred data points across at least four different variables.  \n",
    "2. Investigate the types of variables involved, their likely distributions, and their relationships with each other.  \n",
    "3. Synthesise/simulate a data set as closely matching their properties as possible.  \n",
    "4. Detail your research and implement the simulation in a Jupyter notebook â€“ the data set itself can simply be displayed in an output cell within the notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7c0aa-84c1-46ad-ad00-719ce0413fa8",
   "metadata": {},
   "source": [
    "### 1.2 Choice of real world phenomenon  \n",
    "The dataset I have chosen to synthesise is not a big data set but it is of interest to me as I like to try to be a healthy eater. This as with many things in life does not always go according to plan. Although I will say it does help to be as informed as possible.  \n",
    "<br>\n",
    "The dataset I have chosen to synthesise is the Nutrition data on 77 cereal products. \n",
    "I obtained this data from the website Kaggle.com. Here is the link to the page: https://www.kaggle.com/datasets/crawford/80-cereals?resource=download&select=cereal.csv  \n",
    "<br>\n",
    "Cereals are an intersting case study as for many cerals are seen as one of the staples of a healthy diet, when in actual fact, the exact opposite can be true depending on your choice as many are loaded with hidden sugars that the advertising and the smiling person in the advertisment do not tell you. \n",
    "For me, when I was growing up I often used a bowl of cereal as a snack at any time of the day, this continued well into adulthood and I suppose I really can only blame myself for thinking that I was actually choosing the \"healthy\" option when I was loading up the bowl with something called \"Sugar Puffs\", \"Frosted Wheats\" and/or \"Coco Pops\". \n",
    "I choose this data set as it contains the nutritional information of 77 different brands of cereal, and although the primary goal of this project is to attempt to synthasise a dataset with similar distributions and properties, I may learn something of nutritional value along the way.  \n",
    "<br>\n",
    "There are a number of variables that must be considerd when looking at the nutritional value of any food and cereals are no different. The obvious nutritional information many people look for when they pick up a package of food is calorie count, sugars, fat, carbohydrates and to a lesser extent in my personal opion fiber and protein(unless you are attempting to build muscle - a phase I got into in my late 20's, forgotten now). This information is provided for each cereal and there is some more, including an overall rating. It is not clear from the original dataset or kaggle how this rating is determined, however it is suggested it may be from consumer reports. One of my tasks during the analysis phase will be to see does this rating corrolate with any of the other data. Information such as if the cereal is eaten hot or cold, and what shelf the cereal is normally displayed on is also provided, this will be interesting to see if the high sugar content cereals aimed primarily at children are placed on the lower shelves. I will go through each column from the original dataset in a section below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb8b87-5f9e-4af0-b16d-70e9881c5f6e",
   "metadata": {},
   "source": [
    "# 1.3 Investigate the Variables\n",
    "I will investigate the types of variables of the original dataset, their likely distributions, and their relationships with each other in an attemt to understand the data better for synthesis.  \n",
    "<br>\n",
    "I will attempt to analyse the data using tools from differnt python libaries such as pandas, matplotlib and seaborne. Some of these tools will be used to read in the data and provide statistical information while others will generate plots such as pairplots, histograms and scatter plots in order to attempt to determine distributions of the data types and corrolations between some of the factors. Because there are 16 columns of data I am sure I will miss some of these corrolations. However I will try to highlight the obvious ones during the analysis phase and replicate those corrolations in my synthisised data set. I may even leave out trying to simulate some of the data from the original datasets if I feel that it is getting too complex.  \n",
    "<br>\n",
    "However the goal from the outset is to attempt to simulate a dataset that is as close to the real world scenario as possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f74116-1405-477a-bb6d-abf10b9128a4",
   "metadata": {},
   "source": [
    "# 1.4 Synthesising the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c99003-e52b-4fb1-a458-a7e5532f2457",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eada2b1-393d-49ca-8c2e-272fec005846",
   "metadata": {},
   "source": [
    "# 1.5 Detailing the research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c1964-3a36-409a-bff6-2ead71b33277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d018cd-7c4e-436b-8368-dc49e2ef1daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb88ac81-576e-4669-83a0-5c91d62b522a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d98d7-64c4-4f77-bacd-f0f764d70b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "The original dataset I decided to attempt to syntesise has 16 columns. In the first 3 columns the data type is strings. These columns are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8431c6-584f-40ac-a11b-adf8d757d0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc172d-43dc-4939-b2b1-7071a7444f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3eee70-4be4-461b-82f8-3c52cde44e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d648f6a-1057-4470-b0fc-f0d1fbf5e198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "501e7ea7-d9cc-4c20-ae52-ed932225262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of countries by appending number to 'country'\n",
    "cereal =[]\n",
    "# use for loop and concatenate number to string\n",
    "for i in range(80):\n",
    "    cerealname = 'Sim_Cereal_'+str(i)\n",
    "    # append countryname  to list of countries\n",
    "    cereal.append(cerealname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53cd46bd-203f-4ea8-84c6-6090b48053ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sim_Cereal_0',\n",
       " 'Sim_Cereal_1',\n",
       " 'Sim_Cereal_2',\n",
       " 'Sim_Cereal_3',\n",
       " 'Sim_Cereal_4',\n",
       " 'Sim_Cereal_5',\n",
       " 'Sim_Cereal_6',\n",
       " 'Sim_Cereal_7',\n",
       " 'Sim_Cereal_8',\n",
       " 'Sim_Cereal_9',\n",
       " 'Sim_Cereal_10',\n",
       " 'Sim_Cereal_11',\n",
       " 'Sim_Cereal_12',\n",
       " 'Sim_Cereal_13',\n",
       " 'Sim_Cereal_14',\n",
       " 'Sim_Cereal_15',\n",
       " 'Sim_Cereal_16',\n",
       " 'Sim_Cereal_17',\n",
       " 'Sim_Cereal_18',\n",
       " 'Sim_Cereal_19',\n",
       " 'Sim_Cereal_20',\n",
       " 'Sim_Cereal_21',\n",
       " 'Sim_Cereal_22',\n",
       " 'Sim_Cereal_23',\n",
       " 'Sim_Cereal_24',\n",
       " 'Sim_Cereal_25',\n",
       " 'Sim_Cereal_26',\n",
       " 'Sim_Cereal_27',\n",
       " 'Sim_Cereal_28',\n",
       " 'Sim_Cereal_29',\n",
       " 'Sim_Cereal_30',\n",
       " 'Sim_Cereal_31',\n",
       " 'Sim_Cereal_32',\n",
       " 'Sim_Cereal_33',\n",
       " 'Sim_Cereal_34',\n",
       " 'Sim_Cereal_35',\n",
       " 'Sim_Cereal_36',\n",
       " 'Sim_Cereal_37',\n",
       " 'Sim_Cereal_38',\n",
       " 'Sim_Cereal_39',\n",
       " 'Sim_Cereal_40',\n",
       " 'Sim_Cereal_41',\n",
       " 'Sim_Cereal_42',\n",
       " 'Sim_Cereal_43',\n",
       " 'Sim_Cereal_44',\n",
       " 'Sim_Cereal_45',\n",
       " 'Sim_Cereal_46',\n",
       " 'Sim_Cereal_47',\n",
       " 'Sim_Cereal_48',\n",
       " 'Sim_Cereal_49',\n",
       " 'Sim_Cereal_50',\n",
       " 'Sim_Cereal_51',\n",
       " 'Sim_Cereal_52',\n",
       " 'Sim_Cereal_53',\n",
       " 'Sim_Cereal_54',\n",
       " 'Sim_Cereal_55',\n",
       " 'Sim_Cereal_56',\n",
       " 'Sim_Cereal_57',\n",
       " 'Sim_Cereal_58',\n",
       " 'Sim_Cereal_59',\n",
       " 'Sim_Cereal_60',\n",
       " 'Sim_Cereal_61',\n",
       " 'Sim_Cereal_62',\n",
       " 'Sim_Cereal_63',\n",
       " 'Sim_Cereal_64',\n",
       " 'Sim_Cereal_65',\n",
       " 'Sim_Cereal_66',\n",
       " 'Sim_Cereal_67',\n",
       " 'Sim_Cereal_68',\n",
       " 'Sim_Cereal_69',\n",
       " 'Sim_Cereal_70',\n",
       " 'Sim_Cereal_71',\n",
       " 'Sim_Cereal_72',\n",
       " 'Sim_Cereal_73',\n",
       " 'Sim_Cereal_74',\n",
       " 'Sim_Cereal_75',\n",
       " 'Sim_Cereal_76',\n",
       " 'Sim_Cereal_77',\n",
       " 'Sim_Cereal_78',\n",
       " 'Sim_Cereal_79']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cereal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01fe5af-429c-4432-997e-e421ccab5ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
